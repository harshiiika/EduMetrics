# EduMetrics
An end-to-end learning analytics system that processes educational data, applies statistical analysis and machine learning, and generates predictive insights and personalized recommendations.

## ğŸ¯ Project Overview

This project demonstrates the ability to :-)
-> Process and analyze educational data at scale
- Generate meaningful insights using statistical methods and ML
-> Create predictive models for student performance
- Build data visualizations for non-technical stakeholders
-> Design scalable data pipelines with proper architecture

## âœ¨ Key Features

### 1. Performance Analytics
- Individual student performance summaries
- Subject and topic-level analysis
- Improvement trend detection using **Linear regression**
- Statistical analysis (mean, median, standard deviation)

### 2. Predictive Analytics
- Performance prediction for upcoming assessments
- **Weighted moving average** algorithm
- Confidence scoring based on historical consistency
- Trend-based forecasting

### 3. Personalized Recommendations
- Identifies weak topics requiring attention
- Analyzes study patterns and habits
- Generates prioritized, actionable suggestions
- Data-driven learning strategies

### 4. Class-Level Insights
- Overall class performance metrics
- Subject difficulty analysis
- Student segmentation (top performers vs. struggling students)
- Engagement analytics

### 5. Data Visualization
- **Progress tracking charts** - Score progression over time with trend lines
- **Subject performance comparisons** - Bar charts with statistical indicators
- **Topic performance heatmaps** - Color-coded grids showing strengths/weaknesses
- **Study pattern analysis** - Time investment vs. completion rates
- **Class distribution visualizations** - Performance histograms and trends

## ğŸ“Š Sample Results

**Dataset GeneratedğŸ“˜:-> **
- **100 students** analyzed
- **2,513 assessments** processed
- **22,217 study sessions** tracked
- **6 months** of historical data
- **5 subjects**, **25 topics** covered

**Insights Generated:**
- Individual performance trends (improving/stable/declining)
- Topic-specific strengths and weaknesses
- Predictive scores with confidence levels
- Personalized study recommendations
- Class-level performance patterns

## ğŸ› ï¸ Technologies Used

### Core Technologies
- **Python 3.12+** - Primary programming language
- **pandas** - Data manipulation and analysis
- **NumPy** - Numerical computations and array operations
- **scikit-learn** - Machine learning (Linear Regression)
- **matplotlib** - Data visualization
- **seaborn** - Statistical graphics

### Key Algorithms & Techniques
1. **Linear Regression** - Trend analysis and improvement detection
2. **Weighted Moving Average** - Performance prediction
3. **Statistical Analysis** - Mean, median, std dev, confidence intervals
4. **Data Aggregation** - Multi-dimensional performance analysis
5. **Time Series Analysis** - Progress tracking over time

## ğŸ“ Project Structure

```
insightdashboard/
â”œâ”€â”€ dashboard.py              # Main application orchestrator
â”œâ”€â”€ data_generator.py         # Generates realistic student data
â”œâ”€â”€ insights_analyzer.py      # Core analytics logic (BRAIN)
â”œâ”€â”€ visualizer.py            # Creates charts and visualizations
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # This file
â”‚
â”œâ”€â”€ data/                   # Generated datasets
â”‚   â”œâ”€â”€ students.csv
â”‚   â”œâ”€â”€ assessments.csv
â”‚   â””â”€â”€ study_sessions.csv
â”‚
â”œâ”€â”€ reports/                # Generated insight reports
â”‚   â”œâ”€â”€ STU001_report.json
â”‚   â”œâ”€â”€ STU002_report.json
|   â”œâ”€â”€ STU003_report.json
â”‚   â””â”€â”€ class_insights.json
â”‚
â””â”€â”€ visualizations/         # Generated charts (PNG)
    â”œâ”€â”€ STU001_progress.png
    â”œâ”€â”€ STU001_subjects.png
    â”œâ”€â”€ STU001_heatmap.png
    â”œâ”€â”€ STU001_study_patterns.png
    â”œâ”€â”€ class_overview.png
    â””â”€â”€ class_trends.png
```

## ğŸš€ How to Run

### Prerequisites
```bash
Python 3.12 or higher
pip (Python package manager)
```

### Installation
```bash
# Clone the repository
git clone https://github.com/yourusername/student-insights-dashboard.git
cd insightdashboard

# Install dependencies
pip install -r requirements.txt
```

### Running the Dashboard
```bash
# Run the complete demo
python dashboard.py
```

This will:
1. Generate sample data for 100 students
2. Analyze performance and create insights
3. Generate visualizations
4. Save reports to `reports/` and `visualizations/`

### Expected Output
```
============================================================
STUDENT LEARNING INSIGHTS DASHBOARD - DEMO
============================================================

Generating student profiles...
Generating assessment data...
Generating study sessions...

âœ“ Generated data for 100 students
âœ“ Total assessments: 2513
âœ“ Total study sessions: 22217

[... detailed class and student insights ...]

DEMO COMPLETED SUCCESSFULLY!
```

## ğŸ§® Core Analytics Logic

### 1. Trend Detection (Linear Regression)
```python
# Analyzes score progression over time
X = assessment_sequence_numbers
y = assessment_scores

model = LinearRegression()
model.fit(X, y)

slope = model.coef_[0]
# Positive slope â†’ Improving
# Negative slope â†’ Declining
# ~Zero slope â†’ Stable
```

**Output:** Categorized as "Strong Improvement", "Moderate Improvement", "Stable", "Slight Decline", or "Needs Attention"

### 2. Performance Prediction (Weighted Moving Average)
```python
# Recent scores weighted higher
recent_scores = [70, 72, 75, 78, 80]  # Last 5 assessments
weights = [0.1, 0.15, 0.2, 0.25, 0.3]  # Recent = higher weight

predicted_score = weighted_average(recent_scores, weights)
confidence = calculate_confidence(std_deviation)
```

**Output:** Predicted score with confidence level (High/Medium/Low)

### 3. Weak Topic Identification (Data Aggregation)
```python
# Group by subject and topic, calculate averages
topic_performance = assessments.groupby(['subject', 'topic'])['score'].mean()

# Filter topics below threshold
weak_topics = topic_performance[topic_performance < 70]

# Sort by severity
weak_topics_sorted = weak_topics.sort_values()
```

**Output:** Prioritized list of topics needing attention

### 4. Recommendation Engine (Rule-Based Logic)
```python
recommendations = []

# Rule 1: Skill gaps (highest priority)
if weak_topics:
    recommendations.append({
        'priority': 'High',
        'message': f'Focus on: {weak_topics}'
    })

# Rule 2: Study habits
if completion_rate < 70%:
    recommendations.append({
        'priority': 'Medium',
        'message': 'Improve study session completion'
    })

# Rule 3: Time management
if avg_time_per_assessment < 20 minutes:
    recommendations.append({
        'priority': 'Low',
        'message': 'Spend more time on assessments'
    })
```

**Output:** Prioritized, actionable recommendations

## ğŸ“ˆ Sample Insights Report

```json
{
  "student_id": "STU001",
  "performance_summary": {
    "average_score": 85.50,
    "total_assessments": 20,
    "best_subject": "Science",
    "weakest_subject": "English",
    "improvement_trend": "Stable",
    "study_completion_rate": 87.0
  },
  "weak_topics": [],
  "strong_topics": [
    {"subject": "Science", "topic": "Biology", "avg_score": 93.62}
  ],
  "subject_predictions": {
    "Mathematics": {
      "prediction": 84.41,
      "confidence": "Medium",
      "recent_trend": "Strong Improvement"
    }
  },
  "recommendations": []
}
```

## ğŸ“ Skills Demonstrated

### Data Analysis
âœ… Data collection and structuring  
âœ… Statistical analysis (mean, median, std dev, correlation)  
âœ… Trend detection and pattern recognition  
âœ… Multi-dimensional data aggregation  

### Machine Learning
âœ… Linear regression implementation  
âœ… Prediction modeling with confidence scoring  
âœ… Feature engineering (weighted averages)  
âœ… Model validation (trend consistency)  

### Software Engineering
âœ… Modular architecture (separation of concerns)  
âœ… Clean code with documentation  
âœ… Error handling and validation  
âœ… Scalable design patterns  

### Data Visualization
âœ… Multiple chart types (line, bar, heatmap)  
âœ… Color coding for accessibility  
âœ… Statistical overlays (trend lines, averages)  
âœ… Professional-quality outputs  

## ğŸ”„ Real-World Application

This POC demonstrates capabilities directly relevant to EdTech platforms, And especially for students academic improvements:

1. **Data Integration** - Simulates collecting data from learning platforms
2. **Insight Generation** - Transforms raw data into actionable intelligence
3. **Scalability** - Modular architecture allows easy expansion
4. **Transparency** - Clear logic and verification structure
5. **User Accessibility** - Visualizations make insights understandable

## ğŸš€ Future Enhancements

- [ ] Integration with real educational APIs (Canvas, Google Classroom)
- [ ] Advanced ML models (Random Forest, Neural Networks)
- [ ] Real-time data processing and streaming analytics
- [ ] Interactive web dashboard (React/Flask)
- [ ] A/B testing framework for interventions
- [ ] Natural language generation for insight summaries

## ğŸ“š Learning Resources Used

- **Pandas Documentation** - Data manipulation techniques
- **Scikit-learn Guide** - Linear regression implementation
- **Kaggle Learn** - Data visualization best practices
- **Statistical Methods** - Weighted averages, confidence intervals
- **Data Science Best Practices** - Pipeline design, modular architecture

## ğŸ‘¨â€ğŸ’» Author

**Harshika Saxena**  
Computer Science Student | Data Analytics Enthusiast  
- Email: harshikasaxena01@gmail.com
- LinkedIn: [linkedin.com/in/harshika-saxena](https://www.linkedin.com/in/harshika-saxena/)
- GitHub: [github.com/harshiiika](https://github.com/harshiiika)

## ğŸ“„ License

This project was created as a proof-of-concept for demonstrating data analytics capabilities.

---

## ğŸ¯ Why This Project?

I built this POC to demonstrate my ability to:
1. **Execute** - Turn concepts into working implementations
2. **Analyze** - Apply statistical methods and ML to real-world problems
3. **Scale** - Design maintainable, production-ready architectures
4. **Communicate** - Make complex data accessible through visualization
5. **Research** - Generate insights that drive decisions, not just display numbers

---
